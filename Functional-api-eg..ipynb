{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_awY5yUD3cn",
        "outputId": "a6149f77-9c4f-4cd6-9876-f372a9738c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - classification_output_accuracy: 0.4876 - classification_output_loss: 0.8162 - loss: 5.8284 - regression_output_loss: 5.0122 - regression_output_mae: 1.8739 - val_classification_output_accuracy: 0.4950 - val_classification_output_loss: 0.8363 - val_loss: 3.2357 - val_regression_output_loss: 2.2968 - val_regression_output_mae: 1.2708\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - classification_output_accuracy: 0.5011 - classification_output_loss: 0.8713 - loss: 2.9050 - regression_output_loss: 2.0337 - regression_output_mae: 1.1324 - val_classification_output_accuracy: 0.4950 - val_classification_output_loss: 0.7899 - val_loss: 2.1702 - val_regression_output_loss: 1.3679 - val_regression_output_mae: 0.9351\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - classification_output_accuracy: 0.5027 - classification_output_loss: 0.7708 - loss: 2.5081 - regression_output_loss: 1.7373 - regression_output_mae: 1.0452 - val_classification_output_accuracy: 0.4900 - val_classification_output_loss: 0.7034 - val_loss: 1.9515 - val_regression_output_loss: 1.2254 - val_regression_output_mae: 0.8930\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - classification_output_accuracy: 0.5155 - classification_output_loss: 0.6998 - loss: 2.3077 - regression_output_loss: 1.6079 - regression_output_mae: 1.0204 - val_classification_output_accuracy: 0.5150 - val_classification_output_loss: 0.6811 - val_loss: 1.7257 - val_regression_output_loss: 1.0365 - val_regression_output_mae: 0.8115\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.5122 - classification_output_loss: 0.6811 - loss: 2.1573 - regression_output_loss: 1.4761 - regression_output_mae: 0.9751 - val_classification_output_accuracy: 0.5300 - val_classification_output_loss: 0.6638 - val_loss: 1.5976 - val_regression_output_loss: 0.9170 - val_regression_output_mae: 0.7650\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.5931 - classification_output_loss: 0.6532 - loss: 1.9460 - regression_output_loss: 1.2929 - regression_output_mae: 0.9009 - val_classification_output_accuracy: 0.5800 - val_classification_output_loss: 0.6399 - val_loss: 1.4935 - val_regression_output_loss: 0.8331 - val_regression_output_mae: 0.7359\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.6236 - classification_output_loss: 0.6329 - loss: 1.7555 - regression_output_loss: 1.1226 - regression_output_mae: 0.8488 - val_classification_output_accuracy: 0.7000 - val_classification_output_loss: 0.6070 - val_loss: 1.4506 - val_regression_output_loss: 0.8152 - val_regression_output_mae: 0.7377\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.6619 - classification_output_loss: 0.6098 - loss: 1.7554 - regression_output_loss: 1.1456 - regression_output_mae: 0.8509 - val_classification_output_accuracy: 0.7250 - val_classification_output_loss: 0.5770 - val_loss: 1.3876 - val_regression_output_loss: 0.7866 - val_regression_output_mae: 0.7250\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.7194 - classification_output_loss: 0.5707 - loss: 1.6919 - regression_output_loss: 1.1212 - regression_output_mae: 0.8635 - val_classification_output_accuracy: 0.7400 - val_classification_output_loss: 0.5467 - val_loss: 1.3434 - val_regression_output_loss: 0.7771 - val_regression_output_mae: 0.7141\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - classification_output_accuracy: 0.7207 - classification_output_loss: 0.5677 - loss: 1.7621 - regression_output_loss: 1.1944 - regression_output_mae: 0.8703 - val_classification_output_accuracy: 0.7800 - val_classification_output_loss: 0.5130 - val_loss: 1.3304 - val_regression_output_loss: 0.7883 - val_regression_output_mae: 0.7276\n",
            "Model reloaded successfully!\n",
            "\n",
            "Training with 32 units\n",
            "\n",
            "Training with 64 units\n",
            "\n",
            "Training with 128 units\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Generate dummy dataset (regression + classification)\n",
        "# ------------------------------\n",
        "# Regression: y = 3x + noise\n",
        "X_reg = np.random.rand(1000, 5)\n",
        "y_reg = 3 * X_reg[:, 0] + 2 * X_reg[:, 1] + np.random.randn(1000)\n",
        "\n",
        "# Classification: binary labels from same X\n",
        "y_clf = (X_reg[:, 0] + X_reg[:, 1] > 1).astype(int)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Functional API Model\n",
        "# ------------------------------\n",
        "inputs = Input(shape=(5,), name=\"input_layer\")\n",
        "\n",
        "# Hidden layers\n",
        "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x = layers.Dropout(0.3)(x)   # prevent overfitting\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "\n",
        "# Two outputs (regression + classification)\n",
        "reg_output = layers.Dense(1, name=\"regression_output\")(x)\n",
        "clf_output = layers.Dense(1, activation=\"sigmoid\", name=\"classification_output\")(x)\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs=inputs, outputs=[reg_output, clf_output], name=\"multi_task_model\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Compile\n",
        "# ------------------------------\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"regression_output\": \"mse\", \"classification_output\": \"binary_crossentropy\"},\n",
        "    metrics={\"regression_output\": \"mae\", \"classification_output\": \"accuracy\"},\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Train\n",
        "# ------------------------------\n",
        "history = model.fit(\n",
        "    X_reg, {\"regression_output\": y_reg, \"classification_output\": y_clf},\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Save and Load\n",
        "# ------------------------------\n",
        "model.save(\"multi_task_model.keras\")\n",
        "reloaded_model = keras.models.load_model(\"multi_task_model.keras\")\n",
        "print(\"Model reloaded successfully!\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Hyperparameter Tuning Example (simple loop)\n",
        "# ------------------------------\n",
        "def build_model(units=64, dropout=0.3):\n",
        "    inputs = Input(shape=(5,))\n",
        "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "for units in [32, 64, 128]:\n",
        "    print(f\"\\nTraining with {units} units\")\n",
        "    temp_model = build_model(units=units)\n",
        "    temp_model.fit(X_reg, y_clf, epochs=5, batch_size=32, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 6. Evaluate the model\n",
        "# ------------------------------\n",
        "results = model.evaluate(\n",
        "    X_reg, {\"regression_output\": y_reg, \"classification_output\": y_clf}, verbose=0\n",
        ")\n",
        "print(\"\\nEvaluation results:\")\n",
        "print(f\"Total Loss: {results[0]:.4f}\")\n",
        "print(f\"Regression Loss (MSE): {results[1]:.4f}, MAE: {results[2]:.4f}\")\n",
        "print(f\"Classification Loss (BCE): {results[3]:.4f}, Accuracy: {results[4]:.4f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 7. Predict on new data\n",
        "# ------------------------------\n",
        "sample_input = X_reg[:5]   # take first 5 samples\n",
        "reg_pred, clf_pred = model.predict(sample_input)\n",
        "\n",
        "print(\"\\nSample Inputs (first 5 rows):\")\n",
        "print(sample_input)\n",
        "\n",
        "print(\"\\nRegression Predictions:\")\n",
        "print(reg_pred.flatten())\n",
        "\n",
        "print(\"\\nClassification Predictions (probabilities):\")\n",
        "print(clf_pred.flatten())\n",
        "\n",
        "print(\"\\nClassification Predictions (class labels):\")\n",
        "print((clf_pred.flatten() > 0.5).astype(int))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urkJ1PUD6nR",
        "outputId": "00ed0dcb-7d97-4c46-e9f8-5e9492dea9b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation results:\n",
            "Total Loss: 1.5038\n",
            "Regression Loss (MSE): 0.9758, MAE: 0.5176\n",
            "Classification Loss (BCE): 0.8000, Accuracy: 0.7958\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\n",
            "Sample Inputs (first 5 rows):\n",
            "[[0.42341509 0.18913936 0.9136621  0.43569519 0.81426491]\n",
            " [0.95283545 0.09160411 0.59090621 0.96642365 0.47217696]\n",
            " [0.32597976 0.02413127 0.28263802 0.29197517 0.793393  ]\n",
            " [0.54372842 0.65346353 0.73212023 0.01959767 0.72947956]\n",
            " [0.37088331 0.71790835 0.762582   0.4947884  0.07308545]]\n",
            "\n",
            "Regression Predictions:\n",
            "[1.6639775 3.000011  1.2324712 2.9976082 2.5101933]\n",
            "\n",
            "Classification Predictions (probabilities):\n",
            "[0.331355   0.4783712  0.3100912  0.6566119  0.65425384]\n",
            "\n",
            "Classification Predictions (class labels):\n",
            "[0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0nxvqm-Ea8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}